{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import string\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WRIST_X</th>\n",
       "      <th>WRIST_Y</th>\n",
       "      <th>WRIST_Z</th>\n",
       "      <th>THUMB_CMC_X</th>\n",
       "      <th>THUMB_CMC_Y</th>\n",
       "      <th>THUMB_CMC_Z</th>\n",
       "      <th>THUMB_MCP_X</th>\n",
       "      <th>THUMB_MCP_Y</th>\n",
       "      <th>THUMB_MCP_Z</th>\n",
       "      <th>THUMB_IP_X</th>\n",
       "      <th>...</th>\n",
       "      <th>PINKY_PIP_X</th>\n",
       "      <th>PINKY_PIP_Y</th>\n",
       "      <th>PINKY_PIP_Z</th>\n",
       "      <th>PINKY_DIP_X</th>\n",
       "      <th>PINKY_DIP_Y</th>\n",
       "      <th>PINKY_DIP_Z</th>\n",
       "      <th>PINKY_TIP_X</th>\n",
       "      <th>PINKY_TIP_Y</th>\n",
       "      <th>PINKY_TIP_Z</th>\n",
       "      <th>LETTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.705129</td>\n",
       "      <td>0.681465</td>\n",
       "      <td>-3.726799e-07</td>\n",
       "      <td>0.655781</td>\n",
       "      <td>0.669596</td>\n",
       "      <td>-0.020477</td>\n",
       "      <td>0.620964</td>\n",
       "      <td>0.609219</td>\n",
       "      <td>-0.024032</td>\n",
       "      <td>0.610217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725396</td>\n",
       "      <td>0.540036</td>\n",
       "      <td>-0.016082</td>\n",
       "      <td>0.719326</td>\n",
       "      <td>0.578124</td>\n",
       "      <td>-0.008699</td>\n",
       "      <td>0.718260</td>\n",
       "      <td>0.590686</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.586547</td>\n",
       "      <td>0.800636</td>\n",
       "      <td>-1.031549e-06</td>\n",
       "      <td>0.480344</td>\n",
       "      <td>0.741624</td>\n",
       "      <td>-0.038213</td>\n",
       "      <td>0.397791</td>\n",
       "      <td>0.585279</td>\n",
       "      <td>-0.039281</td>\n",
       "      <td>0.357303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643567</td>\n",
       "      <td>0.401271</td>\n",
       "      <td>-0.017517</td>\n",
       "      <td>0.630232</td>\n",
       "      <td>0.494887</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.627078</td>\n",
       "      <td>0.525488</td>\n",
       "      <td>0.029565</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.614227</td>\n",
       "      <td>0.490882</td>\n",
       "      <td>-5.055542e-07</td>\n",
       "      <td>0.556846</td>\n",
       "      <td>0.477155</td>\n",
       "      <td>-0.014871</td>\n",
       "      <td>0.515263</td>\n",
       "      <td>0.415900</td>\n",
       "      <td>-0.019213</td>\n",
       "      <td>0.504111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.616749</td>\n",
       "      <td>0.317534</td>\n",
       "      <td>-0.030997</td>\n",
       "      <td>0.617946</td>\n",
       "      <td>0.362212</td>\n",
       "      <td>-0.024809</td>\n",
       "      <td>0.617888</td>\n",
       "      <td>0.398031</td>\n",
       "      <td>-0.013255</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.632437</td>\n",
       "      <td>0.590382</td>\n",
       "      <td>-7.930264e-07</td>\n",
       "      <td>0.551732</td>\n",
       "      <td>0.551491</td>\n",
       "      <td>-0.022800</td>\n",
       "      <td>0.486789</td>\n",
       "      <td>0.447117</td>\n",
       "      <td>-0.026840</td>\n",
       "      <td>0.453469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665542</td>\n",
       "      <td>0.300657</td>\n",
       "      <td>-0.043053</td>\n",
       "      <td>0.657627</td>\n",
       "      <td>0.375538</td>\n",
       "      <td>-0.029377</td>\n",
       "      <td>0.653304</td>\n",
       "      <td>0.423989</td>\n",
       "      <td>-0.010191</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.649473</td>\n",
       "      <td>0.608512</td>\n",
       "      <td>-5.507500e-07</td>\n",
       "      <td>0.593336</td>\n",
       "      <td>0.572877</td>\n",
       "      <td>-0.008319</td>\n",
       "      <td>0.561616</td>\n",
       "      <td>0.511155</td>\n",
       "      <td>-0.011892</td>\n",
       "      <td>0.557620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661274</td>\n",
       "      <td>0.452696</td>\n",
       "      <td>-0.028832</td>\n",
       "      <td>0.656918</td>\n",
       "      <td>0.493891</td>\n",
       "      <td>-0.023145</td>\n",
       "      <td>0.658761</td>\n",
       "      <td>0.526514</td>\n",
       "      <td>-0.012749</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58120</th>\n",
       "      <td>0.734883</td>\n",
       "      <td>0.844581</td>\n",
       "      <td>-3.554977e-07</td>\n",
       "      <td>0.683083</td>\n",
       "      <td>0.837926</td>\n",
       "      <td>-0.033916</td>\n",
       "      <td>0.629622</td>\n",
       "      <td>0.770686</td>\n",
       "      <td>-0.058215</td>\n",
       "      <td>0.641844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768685</td>\n",
       "      <td>0.697841</td>\n",
       "      <td>-0.098630</td>\n",
       "      <td>0.745632</td>\n",
       "      <td>0.750847</td>\n",
       "      <td>-0.088142</td>\n",
       "      <td>0.745765</td>\n",
       "      <td>0.762125</td>\n",
       "      <td>-0.075052</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58121</th>\n",
       "      <td>0.896947</td>\n",
       "      <td>0.818566</td>\n",
       "      <td>-4.967883e-07</td>\n",
       "      <td>0.842692</td>\n",
       "      <td>0.806548</td>\n",
       "      <td>-0.022280</td>\n",
       "      <td>0.788446</td>\n",
       "      <td>0.793346</td>\n",
       "      <td>-0.059241</td>\n",
       "      <td>0.764246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862574</td>\n",
       "      <td>0.846193</td>\n",
       "      <td>-0.130900</td>\n",
       "      <td>0.848402</td>\n",
       "      <td>0.859186</td>\n",
       "      <td>-0.122698</td>\n",
       "      <td>0.842249</td>\n",
       "      <td>0.872296</td>\n",
       "      <td>-0.116242</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58122</th>\n",
       "      <td>0.891786</td>\n",
       "      <td>0.808636</td>\n",
       "      <td>5.736705e-07</td>\n",
       "      <td>0.855437</td>\n",
       "      <td>0.841172</td>\n",
       "      <td>-0.027315</td>\n",
       "      <td>0.823902</td>\n",
       "      <td>0.860068</td>\n",
       "      <td>-0.072829</td>\n",
       "      <td>0.828137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.930016</td>\n",
       "      <td>0.852218</td>\n",
       "      <td>-0.166819</td>\n",
       "      <td>0.917113</td>\n",
       "      <td>0.903268</td>\n",
       "      <td>-0.151303</td>\n",
       "      <td>0.902515</td>\n",
       "      <td>0.931100</td>\n",
       "      <td>-0.140118</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58123</th>\n",
       "      <td>0.874057</td>\n",
       "      <td>0.866110</td>\n",
       "      <td>-1.950414e-07</td>\n",
       "      <td>0.833096</td>\n",
       "      <td>0.874952</td>\n",
       "      <td>-0.033710</td>\n",
       "      <td>0.793079</td>\n",
       "      <td>0.864570</td>\n",
       "      <td>-0.061946</td>\n",
       "      <td>0.784729</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931653</td>\n",
       "      <td>0.821581</td>\n",
       "      <td>-0.119058</td>\n",
       "      <td>0.928594</td>\n",
       "      <td>0.867612</td>\n",
       "      <td>-0.111783</td>\n",
       "      <td>0.930727</td>\n",
       "      <td>0.883792</td>\n",
       "      <td>-0.098778</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58124</th>\n",
       "      <td>0.819167</td>\n",
       "      <td>0.758769</td>\n",
       "      <td>2.368764e-07</td>\n",
       "      <td>0.778192</td>\n",
       "      <td>0.773711</td>\n",
       "      <td>-0.058907</td>\n",
       "      <td>0.757215</td>\n",
       "      <td>0.791815</td>\n",
       "      <td>-0.109385</td>\n",
       "      <td>0.755654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893396</td>\n",
       "      <td>0.846461</td>\n",
       "      <td>-0.144601</td>\n",
       "      <td>0.866693</td>\n",
       "      <td>0.884460</td>\n",
       "      <td>-0.146439</td>\n",
       "      <td>0.846946</td>\n",
       "      <td>0.903754</td>\n",
       "      <td>-0.145430</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58125 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        WRIST_X   WRIST_Y       WRIST_Z  THUMB_CMC_X  THUMB_CMC_Y  \\\n",
       "0      0.705129  0.681465 -3.726799e-07     0.655781     0.669596   \n",
       "1      0.586547  0.800636 -1.031549e-06     0.480344     0.741624   \n",
       "2      0.614227  0.490882 -5.055542e-07     0.556846     0.477155   \n",
       "3      0.632437  0.590382 -7.930264e-07     0.551732     0.551491   \n",
       "4      0.649473  0.608512 -5.507500e-07     0.593336     0.572877   \n",
       "...         ...       ...           ...          ...          ...   \n",
       "58120  0.734883  0.844581 -3.554977e-07     0.683083     0.837926   \n",
       "58121  0.896947  0.818566 -4.967883e-07     0.842692     0.806548   \n",
       "58122  0.891786  0.808636  5.736705e-07     0.855437     0.841172   \n",
       "58123  0.874057  0.866110 -1.950414e-07     0.833096     0.874952   \n",
       "58124  0.819167  0.758769  2.368764e-07     0.778192     0.773711   \n",
       "\n",
       "       THUMB_CMC_Z  THUMB_MCP_X  THUMB_MCP_Y  THUMB_MCP_Z  THUMB_IP_X  ...  \\\n",
       "0        -0.020477     0.620964     0.609219    -0.024032    0.610217  ...   \n",
       "1        -0.038213     0.397791     0.585279    -0.039281    0.357303  ...   \n",
       "2        -0.014871     0.515263     0.415900    -0.019213    0.504111  ...   \n",
       "3        -0.022800     0.486789     0.447117    -0.026840    0.453469  ...   \n",
       "4        -0.008319     0.561616     0.511155    -0.011892    0.557620  ...   \n",
       "...            ...          ...          ...          ...         ...  ...   \n",
       "58120    -0.033916     0.629622     0.770686    -0.058215    0.641844  ...   \n",
       "58121    -0.022280     0.788446     0.793346    -0.059241    0.764246  ...   \n",
       "58122    -0.027315     0.823902     0.860068    -0.072829    0.828137  ...   \n",
       "58123    -0.033710     0.793079     0.864570    -0.061946    0.784729  ...   \n",
       "58124    -0.058907     0.757215     0.791815    -0.109385    0.755654  ...   \n",
       "\n",
       "       PINKY_PIP_X  PINKY_PIP_Y  PINKY_PIP_Z  PINKY_DIP_X  PINKY_DIP_Y  \\\n",
       "0         0.725396     0.540036    -0.016082     0.719326     0.578124   \n",
       "1         0.643567     0.401271    -0.017517     0.630232     0.494887   \n",
       "2         0.616749     0.317534    -0.030997     0.617946     0.362212   \n",
       "3         0.665542     0.300657    -0.043053     0.657627     0.375538   \n",
       "4         0.661274     0.452696    -0.028832     0.656918     0.493891   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "58120     0.768685     0.697841    -0.098630     0.745632     0.750847   \n",
       "58121     0.862574     0.846193    -0.130900     0.848402     0.859186   \n",
       "58122     0.930016     0.852218    -0.166819     0.917113     0.903268   \n",
       "58123     0.931653     0.821581    -0.119058     0.928594     0.867612   \n",
       "58124     0.893396     0.846461    -0.144601     0.866693     0.884460   \n",
       "\n",
       "       PINKY_DIP_Z  PINKY_TIP_X  PINKY_TIP_Y  PINKY_TIP_Z  LETTER  \n",
       "0        -0.008699     0.718260     0.590686     0.001216       A  \n",
       "1         0.003910     0.627078     0.525488     0.029565       A  \n",
       "2        -0.024809     0.617888     0.398031    -0.013255       A  \n",
       "3        -0.029377     0.653304     0.423989    -0.010191       A  \n",
       "4        -0.023145     0.658761     0.526514    -0.012749       A  \n",
       "...            ...          ...          ...          ...     ...  \n",
       "58120    -0.088142     0.745765     0.762125    -0.075052       Z  \n",
       "58121    -0.122698     0.842249     0.872296    -0.116242       Z  \n",
       "58122    -0.151303     0.902515     0.931100    -0.140118       Z  \n",
       "58123    -0.111783     0.930727     0.883792    -0.098778       Z  \n",
       "58124    -0.146439     0.846946     0.903754    -0.145430       Z  \n",
       "\n",
       "[58125 rows x 64 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'LETTER']\n",
    "Y = df['LETTER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WRIST_X</th>\n",
       "      <th>WRIST_Y</th>\n",
       "      <th>WRIST_Z</th>\n",
       "      <th>THUMB_CMC_X</th>\n",
       "      <th>THUMB_CMC_Y</th>\n",
       "      <th>THUMB_CMC_Z</th>\n",
       "      <th>THUMB_MCP_X</th>\n",
       "      <th>THUMB_MCP_Y</th>\n",
       "      <th>THUMB_MCP_Z</th>\n",
       "      <th>THUMB_IP_X</th>\n",
       "      <th>...</th>\n",
       "      <th>PINKY_MCP_Z</th>\n",
       "      <th>PINKY_PIP_X</th>\n",
       "      <th>PINKY_PIP_Y</th>\n",
       "      <th>PINKY_PIP_Z</th>\n",
       "      <th>PINKY_DIP_X</th>\n",
       "      <th>PINKY_DIP_Y</th>\n",
       "      <th>PINKY_DIP_Z</th>\n",
       "      <th>PINKY_TIP_X</th>\n",
       "      <th>PINKY_TIP_Y</th>\n",
       "      <th>PINKY_TIP_Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.705129</td>\n",
       "      <td>0.681465</td>\n",
       "      <td>-3.726799e-07</td>\n",
       "      <td>0.655781</td>\n",
       "      <td>0.669596</td>\n",
       "      <td>-0.020477</td>\n",
       "      <td>0.620964</td>\n",
       "      <td>0.609219</td>\n",
       "      <td>-0.024032</td>\n",
       "      <td>0.610217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003296</td>\n",
       "      <td>0.725396</td>\n",
       "      <td>0.540036</td>\n",
       "      <td>-0.016082</td>\n",
       "      <td>0.719326</td>\n",
       "      <td>0.578124</td>\n",
       "      <td>-0.008699</td>\n",
       "      <td>0.718260</td>\n",
       "      <td>0.590686</td>\n",
       "      <td>0.001216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.586547</td>\n",
       "      <td>0.800636</td>\n",
       "      <td>-1.031549e-06</td>\n",
       "      <td>0.480344</td>\n",
       "      <td>0.741624</td>\n",
       "      <td>-0.038213</td>\n",
       "      <td>0.397791</td>\n",
       "      <td>0.585279</td>\n",
       "      <td>-0.039281</td>\n",
       "      <td>0.357303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008984</td>\n",
       "      <td>0.643567</td>\n",
       "      <td>0.401271</td>\n",
       "      <td>-0.017517</td>\n",
       "      <td>0.630232</td>\n",
       "      <td>0.494887</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.627078</td>\n",
       "      <td>0.525488</td>\n",
       "      <td>0.029565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.614227</td>\n",
       "      <td>0.490882</td>\n",
       "      <td>-5.055542e-07</td>\n",
       "      <td>0.556846</td>\n",
       "      <td>0.477155</td>\n",
       "      <td>-0.014871</td>\n",
       "      <td>0.515263</td>\n",
       "      <td>0.415900</td>\n",
       "      <td>-0.019213</td>\n",
       "      <td>0.504111</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011287</td>\n",
       "      <td>0.616749</td>\n",
       "      <td>0.317534</td>\n",
       "      <td>-0.030997</td>\n",
       "      <td>0.617946</td>\n",
       "      <td>0.362212</td>\n",
       "      <td>-0.024809</td>\n",
       "      <td>0.617888</td>\n",
       "      <td>0.398031</td>\n",
       "      <td>-0.013255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.632437</td>\n",
       "      <td>0.590382</td>\n",
       "      <td>-7.930264e-07</td>\n",
       "      <td>0.551732</td>\n",
       "      <td>0.551491</td>\n",
       "      <td>-0.022800</td>\n",
       "      <td>0.486789</td>\n",
       "      <td>0.447117</td>\n",
       "      <td>-0.026840</td>\n",
       "      <td>0.453469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016421</td>\n",
       "      <td>0.665542</td>\n",
       "      <td>0.300657</td>\n",
       "      <td>-0.043053</td>\n",
       "      <td>0.657627</td>\n",
       "      <td>0.375538</td>\n",
       "      <td>-0.029377</td>\n",
       "      <td>0.653304</td>\n",
       "      <td>0.423989</td>\n",
       "      <td>-0.010191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.649473</td>\n",
       "      <td>0.608512</td>\n",
       "      <td>-5.507500e-07</td>\n",
       "      <td>0.593336</td>\n",
       "      <td>0.572877</td>\n",
       "      <td>-0.008319</td>\n",
       "      <td>0.561616</td>\n",
       "      <td>0.511155</td>\n",
       "      <td>-0.011892</td>\n",
       "      <td>0.557620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012265</td>\n",
       "      <td>0.661274</td>\n",
       "      <td>0.452696</td>\n",
       "      <td>-0.028832</td>\n",
       "      <td>0.656918</td>\n",
       "      <td>0.493891</td>\n",
       "      <td>-0.023145</td>\n",
       "      <td>0.658761</td>\n",
       "      <td>0.526514</td>\n",
       "      <td>-0.012749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58120</th>\n",
       "      <td>0.734883</td>\n",
       "      <td>0.844581</td>\n",
       "      <td>-3.554977e-07</td>\n",
       "      <td>0.683083</td>\n",
       "      <td>0.837926</td>\n",
       "      <td>-0.033916</td>\n",
       "      <td>0.629622</td>\n",
       "      <td>0.770686</td>\n",
       "      <td>-0.058215</td>\n",
       "      <td>0.641844</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069263</td>\n",
       "      <td>0.768685</td>\n",
       "      <td>0.697841</td>\n",
       "      <td>-0.098630</td>\n",
       "      <td>0.745632</td>\n",
       "      <td>0.750847</td>\n",
       "      <td>-0.088142</td>\n",
       "      <td>0.745765</td>\n",
       "      <td>0.762125</td>\n",
       "      <td>-0.075052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58121</th>\n",
       "      <td>0.896947</td>\n",
       "      <td>0.818566</td>\n",
       "      <td>-4.967883e-07</td>\n",
       "      <td>0.842692</td>\n",
       "      <td>0.806548</td>\n",
       "      <td>-0.022280</td>\n",
       "      <td>0.788446</td>\n",
       "      <td>0.793346</td>\n",
       "      <td>-0.059241</td>\n",
       "      <td>0.764246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113046</td>\n",
       "      <td>0.862574</td>\n",
       "      <td>0.846193</td>\n",
       "      <td>-0.130900</td>\n",
       "      <td>0.848402</td>\n",
       "      <td>0.859186</td>\n",
       "      <td>-0.122698</td>\n",
       "      <td>0.842249</td>\n",
       "      <td>0.872296</td>\n",
       "      <td>-0.116242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58122</th>\n",
       "      <td>0.891786</td>\n",
       "      <td>0.808636</td>\n",
       "      <td>5.736705e-07</td>\n",
       "      <td>0.855437</td>\n",
       "      <td>0.841172</td>\n",
       "      <td>-0.027315</td>\n",
       "      <td>0.823902</td>\n",
       "      <td>0.860068</td>\n",
       "      <td>-0.072829</td>\n",
       "      <td>0.828137</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.149001</td>\n",
       "      <td>0.930016</td>\n",
       "      <td>0.852218</td>\n",
       "      <td>-0.166819</td>\n",
       "      <td>0.917113</td>\n",
       "      <td>0.903268</td>\n",
       "      <td>-0.151303</td>\n",
       "      <td>0.902515</td>\n",
       "      <td>0.931100</td>\n",
       "      <td>-0.140118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58123</th>\n",
       "      <td>0.874057</td>\n",
       "      <td>0.866110</td>\n",
       "      <td>-1.950414e-07</td>\n",
       "      <td>0.833096</td>\n",
       "      <td>0.874952</td>\n",
       "      <td>-0.033710</td>\n",
       "      <td>0.793079</td>\n",
       "      <td>0.864570</td>\n",
       "      <td>-0.061946</td>\n",
       "      <td>0.784729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085155</td>\n",
       "      <td>0.931653</td>\n",
       "      <td>0.821581</td>\n",
       "      <td>-0.119058</td>\n",
       "      <td>0.928594</td>\n",
       "      <td>0.867612</td>\n",
       "      <td>-0.111783</td>\n",
       "      <td>0.930727</td>\n",
       "      <td>0.883792</td>\n",
       "      <td>-0.098778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58124</th>\n",
       "      <td>0.819167</td>\n",
       "      <td>0.758769</td>\n",
       "      <td>2.368764e-07</td>\n",
       "      <td>0.778192</td>\n",
       "      <td>0.773711</td>\n",
       "      <td>-0.058907</td>\n",
       "      <td>0.757215</td>\n",
       "      <td>0.791815</td>\n",
       "      <td>-0.109385</td>\n",
       "      <td>0.755654</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112340</td>\n",
       "      <td>0.893396</td>\n",
       "      <td>0.846461</td>\n",
       "      <td>-0.144601</td>\n",
       "      <td>0.866693</td>\n",
       "      <td>0.884460</td>\n",
       "      <td>-0.146439</td>\n",
       "      <td>0.846946</td>\n",
       "      <td>0.903754</td>\n",
       "      <td>-0.145430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58125 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        WRIST_X   WRIST_Y       WRIST_Z  THUMB_CMC_X  THUMB_CMC_Y  \\\n",
       "0      0.705129  0.681465 -3.726799e-07     0.655781     0.669596   \n",
       "1      0.586547  0.800636 -1.031549e-06     0.480344     0.741624   \n",
       "2      0.614227  0.490882 -5.055542e-07     0.556846     0.477155   \n",
       "3      0.632437  0.590382 -7.930264e-07     0.551732     0.551491   \n",
       "4      0.649473  0.608512 -5.507500e-07     0.593336     0.572877   \n",
       "...         ...       ...           ...          ...          ...   \n",
       "58120  0.734883  0.844581 -3.554977e-07     0.683083     0.837926   \n",
       "58121  0.896947  0.818566 -4.967883e-07     0.842692     0.806548   \n",
       "58122  0.891786  0.808636  5.736705e-07     0.855437     0.841172   \n",
       "58123  0.874057  0.866110 -1.950414e-07     0.833096     0.874952   \n",
       "58124  0.819167  0.758769  2.368764e-07     0.778192     0.773711   \n",
       "\n",
       "       THUMB_CMC_Z  THUMB_MCP_X  THUMB_MCP_Y  THUMB_MCP_Z  THUMB_IP_X  ...  \\\n",
       "0        -0.020477     0.620964     0.609219    -0.024032    0.610217  ...   \n",
       "1        -0.038213     0.397791     0.585279    -0.039281    0.357303  ...   \n",
       "2        -0.014871     0.515263     0.415900    -0.019213    0.504111  ...   \n",
       "3        -0.022800     0.486789     0.447117    -0.026840    0.453469  ...   \n",
       "4        -0.008319     0.561616     0.511155    -0.011892    0.557620  ...   \n",
       "...            ...          ...          ...          ...         ...  ...   \n",
       "58120    -0.033916     0.629622     0.770686    -0.058215    0.641844  ...   \n",
       "58121    -0.022280     0.788446     0.793346    -0.059241    0.764246  ...   \n",
       "58122    -0.027315     0.823902     0.860068    -0.072829    0.828137  ...   \n",
       "58123    -0.033710     0.793079     0.864570    -0.061946    0.784729  ...   \n",
       "58124    -0.058907     0.757215     0.791815    -0.109385    0.755654  ...   \n",
       "\n",
       "       PINKY_MCP_Z  PINKY_PIP_X  PINKY_PIP_Y  PINKY_PIP_Z  PINKY_DIP_X  \\\n",
       "0        -0.003296     0.725396     0.540036    -0.016082     0.719326   \n",
       "1         0.008984     0.643567     0.401271    -0.017517     0.630232   \n",
       "2        -0.011287     0.616749     0.317534    -0.030997     0.617946   \n",
       "3        -0.016421     0.665542     0.300657    -0.043053     0.657627   \n",
       "4        -0.012265     0.661274     0.452696    -0.028832     0.656918   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "58120    -0.069263     0.768685     0.697841    -0.098630     0.745632   \n",
       "58121    -0.113046     0.862574     0.846193    -0.130900     0.848402   \n",
       "58122    -0.149001     0.930016     0.852218    -0.166819     0.917113   \n",
       "58123    -0.085155     0.931653     0.821581    -0.119058     0.928594   \n",
       "58124    -0.112340     0.893396     0.846461    -0.144601     0.866693   \n",
       "\n",
       "       PINKY_DIP_Y  PINKY_DIP_Z  PINKY_TIP_X  PINKY_TIP_Y  PINKY_TIP_Z  \n",
       "0         0.578124    -0.008699     0.718260     0.590686     0.001216  \n",
       "1         0.494887     0.003910     0.627078     0.525488     0.029565  \n",
       "2         0.362212    -0.024809     0.617888     0.398031    -0.013255  \n",
       "3         0.375538    -0.029377     0.653304     0.423989    -0.010191  \n",
       "4         0.493891    -0.023145     0.658761     0.526514    -0.012749  \n",
       "...            ...          ...          ...          ...          ...  \n",
       "58120     0.750847    -0.088142     0.745765     0.762125    -0.075052  \n",
       "58121     0.859186    -0.122698     0.842249     0.872296    -0.116242  \n",
       "58122     0.903268    -0.151303     0.902515     0.931100    -0.140118  \n",
       "58123     0.867612    -0.111783     0.930727     0.883792    -0.098778  \n",
       "58124     0.884460    -0.146439     0.846946     0.903754    -0.145430  \n",
       "\n",
       "[58125 rows x 63 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        A\n",
       "1        A\n",
       "2        A\n",
       "3        A\n",
       "4        A\n",
       "        ..\n",
       "58120    Z\n",
       "58121    Z\n",
       "58122    Z\n",
       "58123    Z\n",
       "58124    Z\n",
       "Name: LETTER, Length: 58125, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "INCLUDE_Z_PARAMETER = True\n",
    "\n",
    "if not INCLUDE_Z_PARAMETER:\n",
    "    X = X.filter(regex='_[XY]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "encoder = preprocessing.OneHotEncoder()\n",
    "encoder.fit_transform([[letter] for letter in string.ascii_uppercase])\n",
    "\n",
    "y = encoder.transform(Y.to_numpy().reshape(Y.shape[0], 1)).toarray()\n",
    "y = np.argmax(y, axis=1)\n",
    "\n",
    "num_classes = len(encoder.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-20 11:49:26.617888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 11:49:26.622452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 11:49:26.622907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 11:49:26.623836: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-20 11:49:26.625167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 11:49:26.625456: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 11:49:26.625683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 11:49:27.021774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 11:49:27.022144: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 11:49:27.022452: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 11:49:27.022866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1895 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "def make_model(input_shape):\n",
    "    model = Sequential([\n",
    "        layers.Input(input_shape),\n",
    "        \n",
    "        layers.Dense(200, use_bias=False, kernel_initializer=\"he_normal\"),\n",
    "        layers.BatchNormalization(center=True, scale=False),\n",
    "        layers.Activation('relu'),\n",
    "        \n",
    "        layers.Dense(100, use_bias=False, kernel_initializer=\"he_normal\"),\n",
    "        layers.BatchNormalization(center=True, scale=False),\n",
    "        layers.Activation('relu'),\n",
    "        \n",
    "        layers.Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = make_model(input_shape=X_train.shape[1:])\n",
    "#keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./logs/\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-4800d4ad6d698604\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-4800d4ad6d698604\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "582/582 [==============================] - 4s 5ms/step - loss: 0.2347 - accuracy: 0.9360 - val_loss: 1.6078 - val_accuracy: 0.5427 - lr: 0.0100\n",
      "Epoch 2/10\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 0.0904 - accuracy: 0.9726 - val_loss: 2.4783 - val_accuracy: 0.4777 - lr: 0.0060\n",
      "Epoch 3/10\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 0.0598 - accuracy: 0.9815 - val_loss: 0.2631 - val_accuracy: 0.9097 - lr: 0.0036\n",
      "Epoch 4/10\n",
      "582/582 [==============================] - 3s 5ms/step - loss: 0.0414 - accuracy: 0.9882 - val_loss: 0.1657 - val_accuracy: 0.9472 - lr: 0.0022\n",
      "Epoch 5/10\n",
      "582/582 [==============================] - 3s 5ms/step - loss: 0.0314 - accuracy: 0.9906 - val_loss: 0.0486 - val_accuracy: 0.9882 - lr: 0.0013\n",
      "Epoch 6/10\n",
      "582/582 [==============================] - 2s 4ms/step - loss: 0.0270 - accuracy: 0.9925 - val_loss: 0.0576 - val_accuracy: 0.9805 - lr: 7.7760e-04\n",
      "Epoch 7/10\n",
      "582/582 [==============================] - 3s 5ms/step - loss: 0.0239 - accuracy: 0.9933 - val_loss: 0.0379 - val_accuracy: 0.9896 - lr: 4.6656e-04\n",
      "Epoch 8/10\n",
      "582/582 [==============================] - 3s 5ms/step - loss: 0.0223 - accuracy: 0.9937 - val_loss: 0.0317 - val_accuracy: 0.9920 - lr: 2.7994e-04\n",
      "Epoch 9/10\n",
      "582/582 [==============================] - 3s 5ms/step - loss: 0.0209 - accuracy: 0.9943 - val_loss: 0.0252 - val_accuracy: 0.9935 - lr: 1.6796e-04\n",
      "Epoch 10/10\n",
      "582/582 [==============================] - 3s 5ms/step - loss: 0.0191 - accuracy: 0.9949 - val_loss: 0.0262 - val_accuracy: 0.9932 - lr: 1.0078e-04\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "model_name = \"asl_alphabet_neuralnetwork\"\n",
    "\n",
    "os.makedirs(os.path.join(\"models\", \"tfjs\"), exist_ok=True)\n",
    "\n",
    "def lr_decay(epoch, lr):\n",
    "    return 0.01 * math.pow(0.6, epoch)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.LearningRateScheduler(lr_decay, verbose=False),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(\"models\", f\"{model_name}.h5\"), save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    tensorboard_callback\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.00001),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(os.path.join(\"models\", f\"{model_name}.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364/364 [==============================] - 1s 2ms/step - loss: 0.0248 - accuracy: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.024765320122241974, 0.9938924908638]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-20 11:50:00.727070: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 11:50:00.731914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 11:50:00.732169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 11:50:00.738703: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-20 11:50:00.739584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 11:50:00.739874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 11:50:00.740060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 11:50:01.089967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 11:50:01.090197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 11:50:01.090383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-20 11:50:01.090557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 459 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2022-03-20 11:50:01.508124: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "INFO:tensorflow:Assets written to: /tmp/tmp76ay81w_/assets\n",
      "I0320 11:50:01.924101 139849353286016 builder_impl.py:779] Assets written to: /tmp/tmp76ay81w_/assets\n",
      "I0320 11:50:02.350900 139849353286016 lite.py:998] Using new converter: If you encounter a problem please file a bug. You can opt-out by setting experimental_new_converter=False\n",
      "2022-03-20 11:50:02.357653: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\n",
      "2022-03-20 11:50:02.357692: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\n",
      "2022-03-20 11:50:02.358302: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: /tmp/tmp76ay81w_\n",
      "2022-03-20 11:50:02.359912: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\n",
      "2022-03-20 11:50:02.359929: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: /tmp/tmp76ay81w_\n",
      "2022-03-20 11:50:02.367896: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\n",
      "2022-03-20 11:50:02.428602: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: /tmp/tmp76ay81w_\n",
      "2022-03-20 11:50:02.443603: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 85301 microseconds.\n",
      "2022-03-20 11:50:02.464579: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "!tflite_convert --keras_model_file={\"models/\" + model_name + \".h5\"} --output_file={\"models/\" + model_name + \".tflite\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorflowjs_converter --input_format keras {\"models/\" + model_name + \".h5\"} models/tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}